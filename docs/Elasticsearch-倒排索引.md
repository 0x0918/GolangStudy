# Elasticsearch 倒排索引

Elasticsearch 使用一种称为倒排索引的结构，该结构设计来实现非常快速的全文搜索。倒排索引包含了出现在任何文档中的单词列表，以及每个单词出现在的文档列表。

例如，假设我们有两个文档，每个文档都有一个包含以下内容的字段：

1. The quick brown fox jumped over the lazy dog

2. Quick brown foxes leap over lazy dogs in summer

要创建倒排索引，首先将每个文档的内容拆分为单独的索引词（称作 term 或 token），创建所有唯一索引词的排序列表，然后列出每个索引词出现在哪个文档中。结果如下所示：

```text
Term      Doc_1  Doc_2
-------------------------
Quick   |       |  X
The     |   X   |
brown   |   X   |  X
dog     |   X   |
dogs    |       |  X
fox     |   X   |
foxes   |       |  X
in      |       |  X
jumped  |   X   |
lazy    |   X   |  X
leap    |       |  X
over    |   X   |  X
quick   |   X   |
summer  |       |  X
the     |   X   |
------------------------
```

现在，如果我们想搜索 quick brown，我们只需找到每个索引词出现的文档：

```text
Term      Doc_1  Doc_2
-------------------------
brown   |   X   |  X
quick   |   X   |
------------------------
Total   |   2   |  1
```

两个文档都匹配，但第一个文档的匹配项多于第二个文档。如果我们使用一个简单的相似性算法，只计算匹配项的数量，那么我们可以说第一个文档是更好的匹配项（与我们的查询更相关）而不是第二个文档。

当我们目前的倒排索引存在一些问题：

- Quick 和 quick 作为单独的索引词出现，而用户可能认为它们是同一个词。

- fox 和 foxes 很相似，dog 和 dogs 也很相似，它们的词根相同。

- jumped 和 leap 虽然不是来自于同一个词根，但意义相似，它们是同义词。

对于前面的索引，+Quick +fox 的搜索对于任何文档都不匹配（前面的 + 号表示单词必须存在）。为了满足查询，单词 Quick 和 fox 必须位于同一个文档中，但第一个文档包含 quick fox，而第二个文档包含 Quick
foxes。

我们的用户可以合理地期望两个文档都匹配查询。我们可以做的更好。

如果我们将索引词规范化为标准格式，那么我们可以找到包含索引词的文档，这些索引词与用户请求的不完全相同，但相似程度足够确保它们是相关的。例如：

- Quick 可以小写为 quick

- foxes 可以转换为词根 fox，同样地，dogs 可以转换为词根 dog

- jump 和 leap 是同义词，都可以作为 jump 进行索引

现在索引如下所示：

```text
Term      Doc_1  Doc_2
-------------------------
brown   |   X   |  X
dog     |   X   |  X
fox     |   X   |  X
in      |       |  X
jump    |   X   |  X
lazy    |   X   |  X
over    |   X   |  X
quick   |   X   |  X
summer  |       |  X
the     |   X   |  X
------------------------
```

但我们还没有成功。我们对 +Quick +fox 的搜索仍然会失败，因为我们的索引中不再有确切的索引词 Quick。但是，如果我们对查询字符串应用相同的规范化规则，它将变成对 +quick +fox 的查询，这将匹配两个文档。

> 注意：这个操作非常重要。你只能找到索引中存在的索引词，因此索引文本和查询字符串必须规范化为相同的形式

## 不变性

倒排索引被写入磁盘后是不可改变的:它永远不会修改。不变性有重要的价值：

- 不需要锁。如果你从来不更新索引，你就不需要担心多进程同时修改数据的问题。

- 一旦索引被读入内核的文件系统缓存，便会留在哪里，由于其不变性。只要文件系统缓存中还有足够的空间，那么大部分读请求会直接请求内存，而不会命中磁盘。这提供了很大的性能提升。

- 其它缓存(像 filter 缓存)，在索引的生命周期内始终有效。它们不需要在每次数据改变时被重建，因为数据不会变化。

- 写入单个大的倒排索引允许数据被压缩，减少磁盘 I/O 和需要被缓存到内存的索引的使用量。

## 动态更新索引

通过增加新的补充索引来反映新的修改，而不是直接重写整个倒排索引。每一个倒排索引都会被轮流查询到（从最早的开始）查询完后再对结果进行合并。

Elasticsearch 基于 Lucene，引入了按段搜索的概念。每一段本身都是一个倒排索引，但在 Lucene 中除表示所有段的集合外，还增加了提交点的概念。新的文档首先被添加到内存索引缓存中，然后写入到一个基于磁盘的段。

按段搜索会以如下流程进行工作：

1. 新文档被收集到内存索引缓存

2. 不时地, 缓存被提交：

    - 一个新的段(倒排索引)被写入磁盘。

    - 一个新的包含新段名字的提交点被写入磁盘。

    - 磁盘进行同步，所有在文件系统缓存中等待的写入都刷新到磁盘，以确保它们被写入物理文件。

3. 新的段被开启，让它包含的文档可见以被搜索。

4. 内存缓存被清空，等待接收新的文档。

当一个查询被触发，所有已知的段按顺序被查询。词项统计会对所有段的结果进行聚合，以保证每个词和每个文档的关联都被准确计算。 这种方式可以用相对较低的成本将新文档添加到索引。

### 删除和更新

段是不可改变的，所以既不能从把文档从旧的段中移除，也不能修改旧的段来进行反映文档的更新。取而代之的是，每个提交点会包含一个 .del 文件，文件中会列出这些被删除文档的段信息。

当一个文档被 “删除” 时，它实际上只是在 .del 文件中被标记删除。一个被标记删除的文档仍然可以被查询匹配到，但它会在最终结果被返回前从结果集中移除。

文档更新也是类似的操作方式：当一个文档被更新时，旧版本文档被标记删除，文档的新版本被索引到一个新的段中。可能两个版本的文档都会被一个查询匹配到，但被删除的那个旧版本文档在结果集返回前就已经被移除。

### 近实时搜索

随着按段（per-segment）搜索的发展，一个新的文档从索引到可被搜索的延迟显著降低了。新文档在几分钟之内即可被检索，但这样还是不够快。

磁盘在这里成为了瓶颈。提交（Commiting）一个新的段到磁盘需要一个 `fsync` 来确保段被物理性地写入磁盘，这样在断电的时候就不会丢失数据。 但是 `fsync` 操作代价很大;
如果每次索引一个文档都去执行一次的话会造成很大的性能问题。

在 Elasticsearch
和磁盘之间是文件系统缓存。像之前描述的一样，在内存索引缓冲区中的文档会被写入到一个新的段中。但是这里新段会被先写入到文件系统缓存，这一步代价会比较低，稍后再被刷新到磁盘这一步代价比较高。不过只要文件已经在缓存中，就可以像其它文件一样被打开和读取了。

Lucene 允许新段被写入和打开，使其包含的文档在未进行一次完整提交时便对搜索可见。这种方式比进行一次提交代价要小得多，并且在不影响性能的前提下可以被频繁地执行。

#### refresh API

在 Elasticsearch 中，写入和打开一个新段的轻量的过程叫做 refresh 。 默认情况下每个分片会每秒自动刷新一次。这就是为什么我们说 Elasticsearch 是近实时搜索:
文档的变化并不是立即对搜索可见，但会在一秒之内变为可见。

```text
// 刷新（Refresh）所有的索引。
POST /_refresh 

// 只刷新（Refresh） blogs 索引。
POST /blogs/_refresh 
```

### 持久化变更

如果没有用 fsync 把数据从文件系统缓存刷（flush）到硬盘，我们不能保证数据在断电甚至是程序正常退出之后依然存在。为了保证 Elasticsearch 的可靠性，需要确保数据变化被持久化到磁盘。

Elasticsearch 增加了一个 translog ，或者叫事务日志，在每一次对 Elasticsearch 进行操作时均进行了日志记录。通过 translog ，整个流程看起来是下面这样：

1. 一个文档被索引之后，就会被添加到内存缓冲区，并且追加到了 translog。

2. 刷新（refresh）使分片处于刷新（refresh）完成后, 缓存被清空但是事务日志不会的状态，分片每秒被刷新（refresh）一次：

    - 这些在内存缓冲区的文档被写入到一个新的段中，且没有进行 fsync 操作。

    - 这个段被打开，使其可被搜索。

    - 内存缓冲区被清空。

3. 这个进程继续工作，更多的文档被添加到内存缓冲区和追加到事务日志

4. 每隔一段时间，例如 translog 变得越来越大时，索引被刷新（flush）；一个新的 translog 被创建，并且一个全量提交被执行：

    - 所有在内存缓冲区的文档都被写入一个新的段。

    - 缓冲区被清空。

    - 一个提交点被写入硬盘。

    - 文件系统缓存通过 fsync 被刷新（flush）。

    - 老的 translog 被删除。

translog 提供所有还没有被刷到磁盘的操作的一个持久化纪录。当 Elasticsearch 启动的时候，它会从磁盘中使用最后一个提交点去恢复已知的段，并且会重放 translog 中所有在最后一次提交后发生的变更操作。

translog 也被用来提供实时 CRUD。当你试着通过 ID 查询、更新、删除一个文档，它会在尝试从相应的段中检索之前，首先检查 translog 任何最近的变更。这意味着它总是能够实时地获取到文档的最新版本。

### 段合并

由于自动刷新流程每秒会创建一个新的段，这样会导致短时间内的段数量暴增。而段数目太多会带来较大的麻烦。每一个段都会消耗文件句柄、内存和 cpu 运行周期。更重要的是，每个搜索请求都必须轮流检查每个段；所以段越多，搜索也就越慢。

Elasticsearch 通过在后台进行段合并来解决这个问题。小的段被合并到大的段，然后这些大的段再被合并到更大的段。

段合并的时候会将那些旧的已删除文档从文件系统中清除。被删除的文档（或被更新文档的旧版本）不会被拷贝到新的大段中。

启动段合并不需要你做任何事。进行索引和搜索时会自动进行，如下面流程所示：

1. 当索引的时候，刷新（refresh）操作会创建新的段并将段打开以供搜索使用。

2. 合并进程选择一小部分大小相似的段，并且在后台将它们合并到更大的段中。这并不会中断索引和搜索。

3. 下面说明合并完成时的活动：

    - 新的段被刷新（flush）到了磁盘。

    - 新的段被打开用来搜索。

    - 老的段被删除。

合并大的段需要消耗大量的 I/O 和 CPU 资源，如果任其发展会影响搜索性能。Elasticsearch 在默认情况下会对合并流程进行资源限制，所以搜索仍然 有足够的资源很好地执行。

#### optimize API

optimize API 可看做是强制合并 API。它会将一个分片强制合并到 max_num_segments 参数指定大小的段数目。这样做的意图是减少段的数量（通常减少到一个），来提升搜索性能。

在特定情况下，使用 optimize API 颇有益处。例如在日志这种用例下，每天、每周、每月的日志被存储在一个索引中。 老的索引实质上是只读的；它们也并不太可能会发生变化。

在这种情况下，使用 optimize 优化老的索引，将每一个分片合并为一个单独的段就很有用了；这样既可以节省资源，也可以使搜索更加快速：

```text
// 合并索引中的每个分片为一个单独的段
POST /logstash-2014-10/_optimize?max_num_segments=1 
```